{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c3ef31",
   "metadata": {},
   "source": [
    "## Fine-tuning Llama 2 with TDMB data\n",
    "In this guide, I show you how easy it is to leverage Huggingface libraries to finetune Llama 2 with your own dataset. All you need is to put together a json-lines file of your dataset. Huggingface's new trl library will then handle the rest!!\n",
    "\n",
    "All you need is your data in this format:\n",
    "```\n",
    "{\"text\": \"text-for-model-to-predict\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b15ea",
   "metadata": {},
   "source": [
    "And import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceec8b54-af50-4b60-94d2-51c92d9f1dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755c76e48c1c4a729f9f5cb488d938a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments \n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba80137",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Load your train and (optionally) evaluation datasets like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea88109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='IMDBDatasetTrain.json', split='train')  \n",
    "eval_dataset = load_dataset('json', data_files='IMDBDatasetTest.json', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da6ffc",
   "metadata": {},
   "source": [
    "### Formatting prompts\n",
    "Then create a formatting_func to structure training examples as prompts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98725f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['review']}\\n ### Answer: {example['sentiment']}\"\n",
    "    return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e38b3",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Loading model\n",
    "Then we load the Llama 2 non-chat model quantized to 8 bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d235e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guang\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9963169870184a83a17f516acc20e18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_quant_type=\"nf8\",\n",
    "    bnb_8bit_compute_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "# More info: https://github.com/huggingface/transformers/pull/24906\n",
    "base_model.config.pretraining_tp = 1 \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14c9786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23aa1e98-34ee-44ba-878d-59c35b3a4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./Llama-2-7b-hf-fine-tune-TDMB\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-3,\n",
    "    logging_steps=40,\n",
    "    max_steps=80,\n",
    "    logging_dir=\"./logs\",        # Directory for storing logs\n",
    "    save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "    save_steps=40,                # Save checkpoints every 50 steps\n",
    "    evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "    eval_steps=40,               # Evaluate and save checkpoints every 50 steps\n",
    "    do_eval=True                 # Perform evaluation at the end of training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f5edc",
   "metadata": {},
   "source": [
    "We set the config for the Lora adapter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e790d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d8ab6ee-01ff-4ba6-83b3-56342eb5041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92e8338b9d14f46ac7a4d63650cb0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  \n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d3cadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e385d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set max_split_size_mb to a larger value\n",
    "torch.backends.cuda.max_split_size_mb = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b424994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 2:29:57, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.233700</td>\n",
       "      <td>2.399091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.627700</td>\n",
       "      <td>2.721179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.9307075500488282, metrics={'train_runtime': 9118.4919, 'train_samples_per_second': 0.018, 'train_steps_per_second': 0.009, 'total_flos': 6528268417105920.0, 'train_loss': 1.9307075500488282, 'epoch': 3.72})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "# pass in resume_from_checkpoint=True to resume from a checkpoint\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69adefc4",
   "metadata": {},
   "source": [
    "On a 40GB A100, this took about 2 hours ^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2eb12",
   "metadata": {},
   "source": [
    "## Running inference on a trained model\n",
    "By default, the PEFT library will only save the Qlora adapters. So we need to load the base Llama 2 model from the Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffa68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0caf6",
   "metadata": {},
   "source": [
    "and load the qlora adapter from a checkpoint directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93beb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebd71189b2c49bb84565bf4f09fbb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"./Llama-2-7b-hf-fine-tune-TDMB/checkpoint-40\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model =LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e17d1c",
   "metadata": {},
   "source": [
    "then run some inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428d907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "C:\\Users\\guang\\anaconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please give the output: \n",
      "review: As much as it pains me to give a movie called \"Barbie\" a 10 out of 10, I have to do so. It is so brilliantly handled and finely crafted, I have to give the filmakers credit. Yes, I am somewhat conservative person and former law enforcement officer. I'm a guy. I like guy things. Hell I even enjoyed the Battleship movie a few years ago (an absolutely ridiculous but fun romp of an action film). But I also like to experience other perspectives. And man oh man does this movie deliver that in spades - pretty much encapsulated everything my wife has tried to convey about her entire career and life experience wrapped up into two hours! The humor, the sets, the acting, and the ability to weave the current narrative into the story was just perfect. I don't agree with some of the points of the movie, but again, that's ok. This movie wasn't designed to give a balanced perspective of men versus women; it is a no-holds-barred unapologetic crazy ride of a rant about the real issues that women have faced since they were \"allowed\" to have \"real jobs\" and do the same things as men. Give me a well done film that is a blast to watch, that makes you think, and that was done from a place of creativity, passion, and attention to detail, and I'll call it what it is: a 10 out of 10 masterpiece.\n",
      "---\n",
      "sentiment:\n",
      "My 11 year old son and I both love this movie. It is a great family film with a good message. We have seen it many times and it never gets old. We laugh every time we see it and it makes us feel good.\n",
      "---\n",
      "sentiment:\n",
      "What a great movie! I really enjoyed it. It was funny and sweet and very romantic. I would recommend it to anyone.\n",
      "---\n",
      "sentiment:\n",
      "This is a very funny movie\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Please give the output: \n",
    "review: As much as it pains me to give a movie called \"Barbie\" a 10 out of 10, I have to do so. It is so brilliantly handled and finely crafted, I have to give the filmakers credit. Yes, I am somewhat conservative person and former law enforcement officer. I'm a guy. I like guy things. Hell I even enjoyed the Battleship movie a few years ago (an absolutely ridiculous but fun romp of an action film). But I also like to experience other perspectives. And man oh man does this movie deliver that in spades - pretty much encapsulated everything my wife has tried to convey about her entire career and life experience wrapped up into two hours! The humor, the sets, the acting, and the ability to weave the current narrative into the story was just perfect. I don't agree with some of the points of the movie, but again, that's ok. This movie wasn't designed to give a balanced perspective of men versus women; it is a no-holds-barred unapologetic crazy ride of a rant about the real issues that women have faced since they were \"allowed\" to have \"real jobs\" and do the same things as men. Give me a well done film that is a blast to watch, that makes you think, and that was done from a place of creativity, passion, and attention to detail, and I'll call it what it is: a 10 out of 10 masterpiece.\n",
    "---\n",
    "sentiment:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dd841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please give the output: \n",
      "review: Margot Robbie and Ryan Gosling are really great in their roles of Barbie and Kent. Gosling is specially hilarious. I expected a funny, cool, deep and entertaining movie, but I was highly disappointed. The movie is so terribly preachy that ends being an embarrassment. We (the audience) have brains, so, please, preach somewhere else. Furthermore, this is a movie to divide, not to unite. And I'm a woman. The script of the movie is horrendous and the direction is plain bad. There are some great actresses that have too little to say, like Emma Mackey, and that's a pity. Overall: a huge disappointment and a missed opportunity. 3/10 (1 point for Margot Robbie, 1 point for Ryan Gosling, and 1 point for the art direction (super tacky and pinky, as Barbie's world).\n",
      "---\n",
      "sentiment:\n",
      "'The only thing this movie has going for it is the fact that it is a very unique movie. The idea of a movie about a guy who\\'s life is ruined by a dog is a very original concept, but the movie is very poorly executed. The acting is very wooden, and the dialog is very forced. The movie is also very slow, and the jokes are very unfunny. I was very disappointed with this movie, and I would not recommend it\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Please give the output: \n",
    "review: Margot Robbie and Ryan Gosling are really great in their roles of Barbie and Kent. Gosling is specially hilarious. I expected a funny, cool, deep and entertaining movie, but I was highly disappointed. The movie is so terribly preachy that ends being an embarrassment. We (the audience) have brains, so, please, preach somewhere else. Furthermore, this is a movie to divide, not to unite. And I'm a woman. The script of the movie is horrendous and the direction is plain bad. There are some great actresses that have too little to say, like Emma Mackey, and that's a pity. Overall: a huge disappointment and a missed opportunity. 3/10 (1 point for Margot Robbie, 1 point for Ryan Gosling, and 1 point for the art direction (super tacky and pinky, as Barbie's world).\n",
    "---\n",
    "sentiment:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32072015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
